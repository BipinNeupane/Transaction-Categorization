{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11821539,"sourceType":"datasetVersion","datasetId":7425661}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.105052Z","iopub.execute_input":"2025-05-16T18:25:25.105412Z","iopub.status.idle":"2025-05-16T18:25:25.122210Z","shell.execute_reply.started":"2025-05-16T18:25:25.105370Z","shell.execute_reply":"2025-05-16T18:25:25.121357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataframe = pd.read_csv('/kaggle/input/nepali-transaction-dataset/nepali_sensible_transactions_dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.124002Z","iopub.execute_input":"2025-05-16T18:25:25.124698Z","iopub.status.idle":"2025-05-16T18:25:25.147199Z","shell.execute_reply.started":"2025-05-16T18:25:25.124670Z","shell.execute_reply":"2025-05-16T18:25:25.146338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.148775Z","iopub.execute_input":"2025-05-16T18:25:25.149066Z","iopub.status.idle":"2025-05-16T18:25:25.165331Z","shell.execute_reply.started":"2025-05-16T18:25:25.149043Z","shell.execute_reply":"2025-05-16T18:25:25.164429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Removing unnecessary feature \nWe will be removing unnecessary feature based on intiution which could be not very significant fir our model to train on (before further feature engineering)","metadata":{}},{"cell_type":"code","source":"# removed transaction_id and date since it has very less significance to our project\ndataframe.drop(['transaction_id', 'date','location','transaction_type'], axis=1, inplace=True)\ndataframe.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.167896Z","iopub.execute_input":"2025-05-16T18:25:25.168364Z","iopub.status.idle":"2025-05-16T18:25:25.183932Z","shell.execute_reply.started":"2025-05-16T18:25:25.168338Z","shell.execute_reply":"2025-05-16T18:25:25.182959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Dataset Visualization","metadata":{}},{"cell_type":"markdown","source":"## Bar Graph","metadata":{}},{"cell_type":"markdown","source":"Category Distribution visualization","metadata":{}},{"cell_type":"code","source":"category_counts = dataframe[\"category\"].value_counts()\n\nprint(category_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.185209Z","iopub.execute_input":"2025-05-16T18:25:25.185505Z","iopub.status.idle":"2025-05-16T18:25:25.195079Z","shell.execute_reply.started":"2025-05-16T18:25:25.185481Z","shell.execute_reply":"2025-05-16T18:25:25.194317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.countplot(data=dataframe, y='category', order=dataframe['category'].value_counts().index)\nplt.title(\"Category Distribution\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Category\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.196036Z","iopub.execute_input":"2025-05-16T18:25:25.196297Z","iopub.status.idle":"2025-05-16T18:25:25.544790Z","shell.execute_reply.started":"2025-05-16T18:25:25.196275Z","shell.execute_reply":"2025-05-16T18:25:25.543931Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Looking at the graph above we can see the distribution of categories on our dataset with Shopping having the highest count if 121 followed by Others/uncategorized. Food & Groceceries have the least amount of appearance in the dataset with the count of 78. With the above chart we can visualize the distribution of different categories in the dataset for our model","metadata":{}},{"cell_type":"markdown","source":"## WordCloud : Top Words for all categories","metadata":{}},{"cell_type":"code","source":"categories = df['category'].unique()\nn = len(categories)\n\ncols = 2\nrows = (n + 1) // 2 \n\nfig, axes = plt.subplots(rows, cols, figsize=(14, rows * 4))\naxes = axes.flatten()\n\nfor i, cat in enumerate(categories):\n    text = \" \".join(df[df['category'] == cat]['description'].astype(str))\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n\n    axes[i].imshow(wordcloud, interpolation='bilinear')\n    axes[i].axis('off')\n    axes[i].set_title(f\"'{cat}'\", fontsize=12)\n\nfor j in range(i+1, len(axes)):\n    axes[j].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:25.545760Z","iopub.execute_input":"2025-05-16T18:25:25.546000Z","iopub.status.idle":"2025-05-16T18:25:28.632341Z","shell.execute_reply.started":"2025-05-16T18:25:25.545981Z","shell.execute_reply":"2025-05-16T18:25:28.631266Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From above wordcloud we can visualize top words used in the descripiton section in each of the categories.","metadata":{}},{"cell_type":"markdown","source":"## Top 10 words graph","metadata":{}},{"cell_type":"markdown","source":"Below chart shows top 10 words for the selected categories","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=1000)\nX_tfidf = vectorizer.fit_transform(df['description'])\n\nfeature_names = np.array(vectorizer.get_feature_names_out())\n\ntarget_category = 'Others' # This variable can be changed according to the liking for visualization\ncategory_indices = df[df['category'] == target_category].index\ncategory_tfidf = X_tfidf[category_indices].mean(axis=0)\n\ntop_indices = np.argsort(category_tfidf.A1)[-10:]  # top 10 words\n\nplt.barh(feature_names[top_indices], category_tfidf[0, top_indices].A1)\nplt.title(f\"Top TF-IDF Words in '{target_category}'\")\nplt.xlabel(\"TF-IDF Score\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:28.633323Z","iopub.execute_input":"2025-05-16T18:25:28.633628Z","iopub.status.idle":"2025-05-16T18:25:28.823779Z","shell.execute_reply.started":"2025-05-16T18:25:28.633605Z","shell.execute_reply":"2025-05-16T18:25:28.822969Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Drop any rows with missing key data\ndf = df.dropna(subset=[\"description\", \"merchant\", \"amount\", \"category\"])\n\n# seperating Features and labels\nX = df[[\"description\", \"merchant\", \"amount\"]]\ny = df[\"category\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:28.826135Z","iopub.execute_input":"2025-05-16T18:25:28.826349Z","iopub.status.idle":"2025-05-16T18:25:28.833504Z","shell.execute_reply.started":"2025-05-16T18:25:28.826331Z","shell.execute_reply":"2025-05-16T18:25:28.832537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train/test split with sklearn library with a split of 80% to 20% test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:28.834327Z","iopub.execute_input":"2025-05-16T18:25:28.834676Z","iopub.status.idle":"2025-05-16T18:25:28.853357Z","shell.execute_reply.started":"2025-05-16T18:25:28.834657Z","shell.execute_reply":"2025-05-16T18:25:28.852573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pipeline Creation","metadata":{}},{"cell_type":"code","source":"# Column transformer for preprocessing of data, takes in description as TF-IDF tokenizer, Encodes the merchants and scales the amount.\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"desc\", TfidfVectorizer(), \"description\"),\n        ('merchant', OneHotEncoder(handle_unknown='ignore'), ['merchant']),\n        (\"amount\", StandardScaler(), [\"amount\"])\n    ]\n)\n\n# Fit to the entire DataFrame, not just the column\nX_transformed = preprocessor.fit_transform(df)\n\n# Created Pipeline with preprocessor \nmodel_pipeline = Pipeline(steps=[\n    (\"preprocessor\", preprocessor),\n    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:28.854205Z","iopub.execute_input":"2025-05-16T18:25:28.854841Z","iopub.status.idle":"2025-05-16T18:25:28.883447Z","shell.execute_reply.started":"2025-05-16T18:25:28.854809Z","shell.execute_reply":"2025-05-16T18:25:28.882570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Prediction","metadata":{}},{"cell_type":"code","source":"# Training the model with randomforest classifier\nmodel_pipeline.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:28.884411Z","iopub.execute_input":"2025-05-16T18:25:28.884683Z","iopub.status.idle":"2025-05-16T18:25:29.092715Z","shell.execute_reply.started":"2025-05-16T18:25:28.884655Z","shell.execute_reply":"2025-05-16T18:25:29.091947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Making predictions\ny_pred = model_pipeline.predict(X_test)\n\n# Evaluation\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:29.093717Z","iopub.execute_input":"2025-05-16T18:25:29.094008Z","iopub.status.idle":"2025-05-16T18:25:29.131926Z","shell.execute_reply.started":"2025-05-16T18:25:29.093983Z","shell.execute_reply":"2025-05-16T18:25:29.131138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"labels = model_pipeline.classes_\n\ndisp = ConfusionMatrixDisplay.from_predictions(\n    y_test, y_pred, display_labels=labels, xticks_rotation=45,\n    cmap='Blues', colorbar=True\n)\nplt.title(\"Confusion Matrix\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:29.132928Z","iopub.execute_input":"2025-05-16T18:25:29.133201Z","iopub.status.idle":"2025-05-16T18:25:29.527064Z","shell.execute_reply.started":"2025-05-16T18:25:29.133169Z","shell.execute_reply":"2025-05-16T18:25:29.526232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"markdown","source":"After our classification model is done we will try predicting with our custom unseen data (No UI just enter inputs here)","metadata":{}},{"cell_type":"code","source":"\ncustom_input = pd.DataFrame([{\n    \"description\": \"expense\",\n    \"merchant\": \"eSewa\",\n    \"amount\": 200.00\n}])\n\nprediction = model_pipeline.predict(custom_input)\nvectorized_input = preprocessor.transform(custom_input)\n# print(vectorized_input)\nprint(\"Predicted category:\", prediction[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:25:29.527987Z","iopub.execute_input":"2025-05-16T18:25:29.528233Z","iopub.status.idle":"2025-05-16T18:25:29.557611Z","shell.execute_reply.started":"2025-05-16T18:25:29.528213Z","shell.execute_reply":"2025-05-16T18:25:29.556722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}